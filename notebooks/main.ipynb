{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\fakenews_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hello\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hello\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hello\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# nltk_data_path = \"D:/FakeNewsDetection/nltk_data\"\n",
    "# nltk.data.path.append(nltk_data_path)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Ensure the stopwords are loaded from the correct directory\n",
    "stop_words = set(stopwords.words('english', ))\n",
    "punctuation = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(row):\n",
    "    # combine title, subject, and text into one string\n",
    "    combined_text = f\"Title: {row['title']} | Subject: {row['subject']} | Text: {row['text']} \"\n",
    "    # convert to lowercase\n",
    "    text = combined_text.lower()\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # \n",
    "    tokens = [word for word in tokens if word not in punctuation and word not in stop_words]\n",
    "    # \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = pd.read_csv('../data/true.csv')\n",
    "df_fake = pd.read_csv('../data/fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting column 'label' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true['label'] = 1 # 1 for true news\n",
    "df_fake['label'] = 0 # 0 for fake news\n",
    "# Concatenate the two dataframes\n",
    "df = pd.concat([df_true, df_fake], axis=0, ignore_index=True)\n",
    "#spilt 80% of the data for training and 20% for testing\n",
    "#stratify the split by label to ensure both classes are represented in both sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "train_data['processed_text'] = train_data.apply(preprocess_text, axis=1)\n",
    "test_data['processed_text'] = test_data.apply(preprocess_text, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load mô hình BERT nhẹ (paraphrase-MiniLM-L6-v2)\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Hàm tạo embedding theo batch (Không cần torch)\n",
    "def get_batch_embeddings(text_list, batch_size=16):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(text_list), batch_size), desc=\"Embedding...\"):\n",
    "        batch_texts = text_list[i:i+batch_size]\n",
    "        batch_embeddings = model.encode(batch_texts)  # Trả về numpy array\n",
    "        embeddings.extend(batch_embeddings)\n",
    "\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Chuyển train và test thành embedding\n",
    "# X_train = get_batch_embeddings(train_data['processed_text'].tolist(), batch_size=16)\n",
    "# X_test = get_batch_embeddings(test_data['processed_text'].tolist(), batch_size=16)\n",
    "\n",
    "# Lấy nhãn\n",
    "y_train = train_data['label'].values\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "# Kiểm tra kích thước đầu ra\n",
    "# print(\"X_train shape:\", X_train.shape)  # (32000, 384) nếu có 40.000 tin tức\n",
    "# print(\"X_test shape:\", X_test.shape)    # (8000, 384)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../embedding/X_train_embedding.npy', X_train)\n",
    "# np.save('../embedding/X_test_embedding.npy', X_test)\n",
    "\n",
    "# print(\"Embedding đã được lưu vào file .npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=100; total time=  14.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=100; total time=  13.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=100; total time=  13.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=200; total time=  29.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=200; total time=  30.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=200; total time=  25.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=100; total time=  20.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=100; total time=  20.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=100; total time=  21.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=200; total time=  40.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=200; total time=  37.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=200; total time=  37.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=  11.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=  12.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=  11.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=  22.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=  22.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=  22.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=  19.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=  18.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=  18.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=  35.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=  35.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=  38.7s\n",
      "Best parameters found:  {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200}\n",
      "Best cross-validation accuracy:  0.9598252316552127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6],\n",
    "    'learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=cv, scoring='accuracy', n_jobs=1, verbose=2)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train = np.load('../embedding/X_train_embedding.npy')\n",
    "x_test = np.load('../embedding/X_test_embedding.npy')\n",
    "\n",
    "# clf = xgb.XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "# clf.fit(x_train, y_train)\n",
    "\n",
    "# y_pred = clf.predict(x_test)\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
